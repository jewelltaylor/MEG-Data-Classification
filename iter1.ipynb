{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings  \n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from math import sqrt  \n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from statistics import mode \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./csvdata\"\n",
    "agg_path = \"./agg\"\n",
    "results_path = \"./csvdata/results/results_svmgs588_new.csv\"\n",
    "time_interval = 1288\n",
    "\n",
    "svm_parameters = {\n",
    "    'C': (1000000000, 100000, 10000, 1000, 100, 10, 1),\n",
    "    'gamma': (1, .01, .0001, 'auto'),\n",
    "    'kernel': ('linear', 'rbf', 'poly'),\n",
    "    'degree': (2, 3, 4, 5, 6)\n",
    "}\n",
    "\n",
    "rfc_parameters = { \n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(n):\n",
    "    d = defaultdict(int)\n",
    "    for i in range(400, time_interval):\n",
    "        csv_path = agg_path + str(i) + \".csv\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        X = df.iloc[:,0:305] \n",
    "        X = normalize(X)\n",
    "        y = df.iloc[:,-1]\n",
    "        X, y = get_downsampled_data(X, y)\n",
    "        bestfeatures = SelectKBest(score_func=f_classif, k=n)\n",
    "        fit = bestfeatures.fit(X,y)\n",
    "        df_scores = pd.DataFrame(fit.scores_)\n",
    "        best_feature_list = pd.Series(df_scores.sort_values(0)[269:305].index).tolist()\n",
    "        for feature in best_feature_list: \n",
    "            d[feature] += 1\n",
    "        \n",
    "    final_best_feature_list = [(k, v) for k, v in d.items()] \n",
    "    final_best_feature_list = sorted(final_best_feature_list, key=lambda tup: tup[1])\n",
    "    final_best_feature_list = final_best_feature_list[269:305]\n",
    "    final_best_feature_list = [feature for (feature, count) in final_best_feature_list]\n",
    "   \n",
    "    return final_best_feature_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(n):\n",
    "    d = defaultdict(int)\n",
    "    for i in range(400, time_interval):\n",
    "        csv_path = agg_path + str(i) + \".csv\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        X = df.iloc[:,0:305] \n",
    "        X = normalize(X)\n",
    "        y = df.iloc[:,-1]\n",
    "        X, y = get_downsampled_data(X, y)\n",
    "        rfc = RandomForestClassifier()\n",
    "        rfc.fit(X, y)\n",
    "        df_scores = pd.DataFrame(rfc.feature_importances_)\n",
    "        best_feature_list = pd.Series(df_scores.sort_values(0)[269:305].index).tolist()\n",
    "        for feature in best_feature_list: \n",
    "            d[feature] += 1\n",
    "        \n",
    "    final_best_feature_list = [(k, v) for k, v in d.items()] \n",
    "    final_best_feature_list = sorted(final_best_feature_list, key=lambda tup: tup[1])\n",
    "    final_best_feature_list = final_best_feature_list[269:305]\n",
    "    final_best_feature_list = [feature for (feature, count) in final_best_feature_list]\n",
    "   \n",
    "    return final_best_feature_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features3(X, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    column_names = [\"PC\" + str(i) for i in range(1, n+1)]\n",
    "    PCA_X = pd.DataFrame(data = X_pca, columns = column_names)\n",
    "    return PCA_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features4(X, n):\n",
    "    ica = FastICA(n_components=n)\n",
    "    X_ica = ica.fit_transform(X)\n",
    "    column_names = [\"IC\" + str(i) for i in range(1, n+1)]\n",
    "    ICA_X = pd.DataFrame(data = X_ica, columns = column_names)\n",
    "    return ICA_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features5(X, y, n):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_lda = lda.fit(X, Y).transform(X)\n",
    "    column_names = [\"LD\" + str(i) for i in range(1, n+1)]\n",
    "    LDA_X = pd.DataFrame(data = X_lda, columns = column_names)\n",
    "    return LDA_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(X, y):\n",
    "    df = pd.DataFrame(X)\n",
    "    df[\"y\"] = y\n",
    "    n = len(df.index)\n",
    "    correct_num = len(df[df.y==0].index)\n",
    "    incorrect_num = n - correct_num\n",
    "    return correct_num, incorrect_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsampled_data(X, y):\n",
    "    correct_num, incorrect_num = get_class_distribution(X, y)\n",
    "    df = pd.DataFrame(X) \n",
    "    df[\"y\"] = y\n",
    "    df_correct = df[df.y==0]\n",
    "    df_incorrect = df[df.y==1]\n",
    "    \n",
    "    if(correct_num > incorrect_num):\n",
    "        df_correct = df_correct.sample(n=incorrect_num)\n",
    "    else:\n",
    "        df_incorrect = df_incorrect.sample(n=correct_num)\n",
    "    \n",
    "    df = df_correct.append(df_incorrect)\n",
    "    y = df[\"y\"].values\n",
    "    X = df.drop(\"y\", axis=1).values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = get_features()\n",
    "def generate_model():\n",
    "    accuracy_score_list = []\n",
    "    destination_path = path + \"/\" + \"results/results_svmgs1088.csv\"\n",
    "    for i in range(time_interval):\n",
    "        file_path = agg_path + \"/\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        y = df[\"y\"].values\n",
    "        X = df.drop(\"y\", axis=1).values\n",
    "        X = X[:, feature_list]\n",
    "        normalized_X = normalize(X)\n",
    "        accuracy_score = train_model(normalized_X, y)\n",
    "        accuracy_score_list.append(accuracy_score)\n",
    "    \n",
    "    ser = pd.Series(accuracy_score_list)\n",
    "    ser.to_csv(destination_path)\n",
    "    return accuracy_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model2(iterations, sample_size):\n",
    "    accuracy_score_list = []\n",
    "    destination_path = path + \"/\" + \"results/results_svmgs1088.csv\"\n",
    "    for i in range(time_interval):\n",
    "        file_path = agg_path + \"/\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        accuracy_score_sum = 0\n",
    "        for iteration in range(iterations):\n",
    "            cor = df[df.y==0].sample(n=sample_size, replace=True)\n",
    "            incor = df[df.y==1].sample(n=sample_size,  replace=True)\n",
    "            df2 = cor.append(incor)\n",
    "            y = df2[\"y\"].values\n",
    "            X = df2.drop(\"y\", axis=1).values\n",
    "            normalized_X = normalize(X)\n",
    "            accuracy_score = train_model2(normalized_X, y)\n",
    "            accuracy_score_sum += accuracy_score\n",
    "        average_accuracy_score = accuracy_score_sum / iterations\n",
    "        print(average_accuracy_score)\n",
    "        accuracy_score_list.append(average_accuracy_score)\n",
    "    \n",
    "    ser = pd.Series(accuracy_score_list)\n",
    "    ser.to_csv(destination_path)\n",
    "    return accuracy_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model3(sample_size, num_of_models):\n",
    "    accuracy_score_list = []\n",
    "    destination_path = path + \"/\" + \"results/results_svmgs588_new.csv\"\n",
    "    for i in range(time_interval):\n",
    "        file_path = agg_path + \"/\" + str(i) + \".csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        cor = df[df.y==0].sample(n=sample_size)\n",
    "        incor = df[df.y==1].sample(n=sample_size)\n",
    "        df2 = cor.append(incor).sample(len(cor.index) + len(incor.index)).reset_index(drop=True)\n",
    "        y = df2[\"y\"]\n",
    "        X = df2.drop(\"y\", axis=1)\n",
    "        normalized_X = normalize(X)\n",
    "        accuracy_score = train_model3(normalized_X, y, num_of_models)\n",
    "        accuracy_score_list.append(accuracy_score)\n",
    "    \n",
    "    ser = pd.Series(accuracy_score_list)\n",
    "    ser.to_csv(destination_path)\n",
    "    return accuracy_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    kf = KFold()\n",
    "    accuracy_sum = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_int, X_test = X[train_index], X[test_index]\n",
    "        y_int, y_test = y[train_index], y[test_index]\n",
    "        X_train, y_train = get_downsampled_data(X_int, y_int)\n",
    "        rfc = RandomForestClassifier()\n",
    "        clf = GridSearchCV(rfc, model_parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy_sum += metrics.accuracy_score(y_test, predictions)\n",
    "    accuracy_score = accuracy_sum / 3\n",
    "    print(accuracy_score)\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(X, y):\n",
    "    kf = KFold()\n",
    "    accuracy_sum = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_int, X_test = X[train_index], X[test_index]\n",
    "        y_int, y_test = y[train_index], y[test_index]\n",
    "        X_train, y_train = get_downsampled_data(X_int, y_int)\n",
    "        svm = SVC()\n",
    "        clf = GridSearchCV(svm, svm_parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy_sum += metrics.accuracy_score(y_test, predictions)\n",
    "    accuracy_score = accuracy_sum / 3\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model3(X, y, num_of_models):\n",
    "    kf = KFold()\n",
    "    accuracy_sum = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_int, X_test = X[train_index], X[test_index]\n",
    "        y_int, y_test = y[train_index], y[test_index]\n",
    "        print(X_int.shape)\n",
    "        model_predictions = []\n",
    "        df = pd.DataFrame(X_int)\n",
    "        df[\"y\"] = y_int.tolist()\n",
    "        for i in range(num_of_models):\n",
    "            df_sampled = df.sample(len(y_int), replace=True)\n",
    "            y_new = df_sampled[\"y\"]\n",
    "            X_new = df_sampled.drop(\"y\", axis=1)\n",
    "            svm = SVC()\n",
    "            clf = GridSearchCV(svm, svm_parameters)\n",
    "            clf.fit(X_new, y_new)\n",
    "            predictions = clf.predict(X_test)\n",
    "            model_predictions.append(predictions)\n",
    "        \n",
    "        \n",
    "        final_predictions = [None for i in range(len(predictions))]\n",
    "        for i in range(len(predictions)):\n",
    "            temp_list = []\n",
    "            for j in range(len(model_predictions)):\n",
    "                temp_list.append(model_predictions[j][i])\n",
    "                \n",
    "            final_predictions[i] = mode(temp_list)\n",
    "         \n",
    "        final_predictions = pd.Series(model_predictions[0])\n",
    "        accuracy_sum += metrics.accuracy_score(y_test, final_predictions)\n",
    "    accuracy_score = accuracy_sum / 3\n",
    "    print(accuracy_score)\n",
    "    return accuracy_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series():\n",
    "    ser = pd.Series.from_csv(results_path)\n",
    "    x_values = ser.index\n",
    "    y_values = ser.values\n",
    "    poly_degree = 3\n",
    "    coeffs = np.polyfit(x_values, y_values, poly_degree)\n",
    "    poly_eqn = np.poly1d(coeffs)\n",
    "    y_hat = poly_eqn(x_values)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(x_values, y_values, \"ro\")\n",
    "    plt.plot(x_values, y_hat)\n",
    "    plt.title(\"Decoded Time Series\")\n",
    "    plt.xlabel(\"Time Interval\")\n",
    "    plt.ylabel(\"Predcition Accuracy\")\n",
    "    plt.savefig(\"./csvdata/results/timeseriesplot_svmgs588_new.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "generate_model3(88, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
